{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bexlnaRnEqvx"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import time\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4mZicdsEzXD"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8nfHfpzEzfA",
        "outputId": "56eddaac-8773-4ead-98dd-de12c332f82b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJKEStNTEzhn"
      },
      "source": [
        "file = \"/content/drive/MyDrive/Pickle_files/median_values.pkl\"\n",
        "with open(file,'rb') as file:\n",
        "  median_values = pickle.load(file)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjE37s1VnFw5"
      },
      "source": [
        "file = \"/content/drive/MyDrive/Pickle_files/truncated_SVD.pkl\"\n",
        "with open(file,'rb') as file:\n",
        "  Trunc_SVD = pickle.load(file)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_n24n2FnFzB"
      },
      "source": [
        "file = \"/content/drive/MyDrive/Pickle_files/MinMaxSc.pkl\"\n",
        "with open(file,'rb') as file:\n",
        "  MinMaxSc = pickle.load(file)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCXSjmcWnF6P"
      },
      "source": [
        "file = \"/content/drive/MyDrive/Pickle_files/clf_inv.pkl\"\n",
        "with open(file,'rb') as file:\n",
        "  clf_inv = pickle.load(file)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wNlwjHUGP_y"
      },
      "source": [
        "file = \"/content/drive/MyDrive/rf_best.pkl\"\n",
        "with open(file,'rb') as file:\n",
        "  rf_best = pickle.load(file)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAOXj4JhB7UK",
        "outputId": "915606de-cb0b-4be2-8a6d-e8ed59121b6b"
      },
      "source": [
        "load_encoder_model = load_model('/content/drive/MyDrive/Pickle_files/encoder.h5')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEiMxBwNF5pd"
      },
      "source": [
        "file = \"/content/drive/MyDrive/Pickle_files/clf_inv.pkl\"\n",
        "with open(file,'rb') as file:\n",
        "  clf_best = pickle.load(file)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ThVlXBtEzl3",
        "outputId": "ece5202d-2f9f-4cdb-f5dc-a250c08c60c3"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Kaggle_Training_Dataset_v2.csv\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "CcQ21eD5x8Bo",
        "outputId": "c0a424e4-a05f-4d0b-eb37-aaf40feda5b3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sku</th>\n",
              "      <th>national_inv</th>\n",
              "      <th>lead_time</th>\n",
              "      <th>in_transit_qty</th>\n",
              "      <th>forecast_3_month</th>\n",
              "      <th>forecast_6_month</th>\n",
              "      <th>forecast_9_month</th>\n",
              "      <th>sales_1_month</th>\n",
              "      <th>sales_3_month</th>\n",
              "      <th>sales_6_month</th>\n",
              "      <th>sales_9_month</th>\n",
              "      <th>min_bank</th>\n",
              "      <th>potential_issue</th>\n",
              "      <th>pieces_past_due</th>\n",
              "      <th>perf_6_month_avg</th>\n",
              "      <th>perf_12_month_avg</th>\n",
              "      <th>local_bo_qty</th>\n",
              "      <th>deck_risk</th>\n",
              "      <th>oe_constraint</th>\n",
              "      <th>ppap_risk</th>\n",
              "      <th>stop_auto_buy</th>\n",
              "      <th>rev_stop</th>\n",
              "      <th>went_on_backorder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1026827</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1043384</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1043696</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1043852</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1044048</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sku  national_inv  lead_time  ...  stop_auto_buy  rev_stop  went_on_backorder\n",
              "0  1026827           0.0        NaN  ...            Yes        No                 No\n",
              "1  1043384           2.0        9.0  ...            Yes        No                 No\n",
              "2  1043696           2.0        NaN  ...            Yes        No                 No\n",
              "3  1043852           7.0        8.0  ...            Yes        No                 No\n",
              "4  1044048           8.0        NaN  ...            Yes        No                 No\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoKtMZ43x8EI"
      },
      "source": [
        "def final_fun_1(X):\n",
        "  #These Two columns contains more than 95% of 0s\n",
        "  zero_columns = ['pieces_past_due','local_bo_qty']\n",
        "  X = X.drop(columns=zero_columns,axis=1)\n",
        " \n",
        "  # replacing -99 by Nan in performance column\n",
        "  X.perf_6_month_avg.replace({-99.0 : np.nan},inplace=True)\n",
        "  X.perf_12_month_avg.replace({-99.0 : np.nan},inplace=True)\n",
        " \n",
        "  # Converting categories like Yes and No to 0s and 1s\n",
        "  categorical_columns = ['rev_stop','stop_auto_buy','ppap_risk','oe_constraint','deck_risk','potential_issue']\n",
        "  for col in categorical_columns:\n",
        "    X[col].replace({'Yes':1,'No':0},inplace=True)\n",
        "    X[col]=X[col].astype(int)\n",
        " \n",
        "  # Removing outliers points by taking only values below 99 percentile\n",
        "  X = X[(df.national_inv >= 0.000) & (X.national_inv <= 5487.000) & (X.in_transit_qty <= 5510.000 ) &\\\n",
        "      (X.forecast_3_month <= 2280.000) & (X.forecast_6_month <= 4335.659999999916) &\\\n",
        "      (X.forecast_9_month <= 6316.000) & (X.sales_1_month <= 693.000) & (X.sales_3_month <= 2229.000) &\\\n",
        "      (X.sales_6_month <= 4410.000) & (X.sales_9_month <= 6698.000) & (X.min_bank <= 679.6599999999162)]\n",
        "  \n",
        "  # Median Imputation\n",
        "  X = X.fillna(median_values)\n",
        "\n",
        "  # Getting SVD Features\n",
        "  X_svd = Trunc_SVD.transform(X)\n",
        "\n",
        "  # Encoder Model\n",
        "  encoder_X = load_encoder_model.predict(X)\n",
        "\n",
        "  # Dicretisation using Decision Tree\n",
        "  X['national_inv_prob'] = clf_inv.predict_proba(X.national_inv.to_frame())[:,1]\n",
        "\n",
        "  # creating bins for national_inv features\n",
        "  X['national_inv_bins'] = 0\n",
        "  X.loc[(X['national_inv'] == 0.0),'national_inv_bins'] = 1\n",
        "  X.loc[(X['national_inv'] == 1.0),'national_inv_bins'] = 2\n",
        "  X.loc[(X['national_inv'] >= 2.0) & (X['national_inv'] <= 9.0),'national_inv_bins'] = 3\n",
        "  X.loc[(X['national_inv'] >= 10.0),'national_inv_bins'] = 4\n",
        "\n",
        "  # Adding SVD and Encoder features in the main dataframe\n",
        "  for i in range(2):\n",
        "    X['T_SVD_'+str(i)] = X_svd[:,i]\n",
        "    X['AutoEncoder_'+str(i)] = encoder_X[:,i]\n",
        "\n",
        "  cols = X.columns\n",
        "\n",
        "  # Performing MinMaxScaler on Data\n",
        "  X = pd.DataFrame(MinMaxSc.transform(X),columns = cols)\n",
        "\n",
        "  output = rf_best.predict(X)\n",
        "\n",
        "  return output\n",
        "  \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT0UwUCYx8K5",
        "outputId": "74f55416-0983-4521-9c60-2818c25027bf"
      },
      "source": [
        "data_temp = df.head()\n",
        "target_data = df['went_on_backorder']\n",
        "data_temp = data_temp.drop(['sku','went_on_backorder'],axis=1)\n",
        "\n",
        "start_time = time.time()\n",
        "output = final_fun_1(data_temp)\n",
        "print(\"Output : \",output)\n",
        "print(\"Time Taken for execution is {}\".format((time.time() - start_time)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Output :  [0 0 0 0 0]\n",
            "Time Taken for execution is 3.7127180099487305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 361 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ75JNrlG_3C"
      },
      "source": [
        "def final_fun_2(X,Y):\n",
        "  #These Two columns contains more than 95% of 0s\n",
        "  zero_columns = ['pieces_past_due','local_bo_qty']\n",
        "  X = X.drop(columns=zero_columns,axis=1)\n",
        " \n",
        "  # replacing -99 by Nan in performance column\n",
        "  X.perf_6_month_avg.replace({-99.0 : np.nan},inplace=True)\n",
        "  X.perf_12_month_avg.replace({-99.0 : np.nan},inplace=True)\n",
        " \n",
        "  # Converting the Target variable\n",
        "  Y.replace({'Yes':1,'No':0},inplace=True)\n",
        "  Y.astype(int)\n",
        "\n",
        "  # Converting categories like Yes and No to 0s and 1s\n",
        "  categorical_columns = ['rev_stop','stop_auto_buy','ppap_risk','oe_constraint','deck_risk','potential_issue']\n",
        "  for col in categorical_columns:\n",
        "    X[col].replace({'Yes':1,'No':0},inplace=True)\n",
        "    X[col]=X[col].astype(int)\n",
        " \n",
        "  # Appending Target Variable back to dataframe so that we can remove the Outlier rows along with Target variable\n",
        "  X['went_on_backorder'] = Y\n",
        "\n",
        "  # Removing outliers points by taking only values below 99 percentile\n",
        "  X = X[(X.national_inv >= 0.000) & (X.national_inv <= 5487.000) & (X.in_transit_qty <= 5510.000 ) &\\\n",
        "      (X.forecast_3_month <= 2280.000) & (X.forecast_6_month <= 4335.659999999916) &\\\n",
        "      (X.forecast_9_month <= 6316.000) & (X.sales_1_month <= 693.000) & (X.sales_3_month <= 2229.000) &\\\n",
        "      (X.sales_6_month <= 4410.000) & (X.sales_9_month <= 6698.000) & (X.min_bank <= 679.6599999999162)]\n",
        "  \n",
        "  print(\"Shape of outlier free dataframe :\",X.shape)\n",
        "\n",
        "  # Assign the Outlier free Target variable back to Y and Drop the Target variable from main dataframe\n",
        "  Y = X['went_on_backorder']\n",
        "  X = X.drop(columns='went_on_backorder',axis=1)\n",
        "\n",
        "  # Median Imputation\n",
        "  X = X.fillna(median_values)\n",
        "\n",
        "  # Getting SVD Features\n",
        "  X_svd = Trunc_SVD.transform(X)\n",
        "\n",
        "  # Encoder Model\n",
        "  encoder_X = load_encoder_model.predict(X)\n",
        "\n",
        "  # Dicretisation using Decision Tree\n",
        "  X['national_inv_prob'] = clf_inv.predict_proba(X.national_inv.to_frame())[:,1]\n",
        "\n",
        "  # creating bins for national_inv features\n",
        "  X['national_inv_bins'] = 0\n",
        "  X.loc[(X['national_inv'] == 0.0),'national_inv_bins'] = 1\n",
        "  X.loc[(X['national_inv'] == 1.0),'national_inv_bins'] = 2\n",
        "  X.loc[(X['national_inv'] >= 2.0) & (X['national_inv'] <= 9.0),'national_inv_bins'] = 3\n",
        "  X.loc[(X['national_inv'] >= 10.0),'national_inv_bins'] = 4\n",
        "\n",
        "  # Adding SVD and Encoder features in the main dataframe\n",
        "  for i in range(2):\n",
        "    X['T_SVD_'+str(i)] = X_svd[:,i]\n",
        "    X['AutoEncoder_'+str(i)] = encoder_X[:,i]\n",
        "\n",
        "  cols = X.columns\n",
        "\n",
        "  # Performing MinMaxScaler on Data\n",
        "  X = pd.DataFrame(MinMaxSc.transform(X),columns = cols)\n",
        "\n",
        "  output = rf_best.predict(X)\n",
        "  f1 = f1_score(Y,output,average=\"macro\")\n",
        "\n",
        "  return f1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKcyrnXlK_3r",
        "outputId": "c846552f-debd-4cf7-b669-86b770fb99ad"
      },
      "source": [
        "data_temp = df.head(1500)\n",
        "target_data = data_temp['went_on_backorder']\n",
        "data_temp = data_temp.drop(['sku','went_on_backorder'],axis=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Temp shape :  (1500, 21)\n",
            "Target Data shape :  (1500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oboqdGq5K_5-",
        "outputId": "7b277fe9-f15a-47e7-9dfd-946af9fc8a0f"
      },
      "source": [
        "start_time = time.time()\n",
        "output = final_fun_2(data_temp,target_data)\n",
        "print(\"F1_Score : \",output)\n",
        "print(\"Time Taken for execution is {}\".format((time.time() - start_time)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:    0.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of outlier free dataframe : (1466, 20)\n",
            "F1_Score :  0.6994875298940895\n",
            "Time Taken for execution is 0.4376845359802246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done 361 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t72IarkkK_8E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgOAJ-RyK_-x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEHBrb2sG_7F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}